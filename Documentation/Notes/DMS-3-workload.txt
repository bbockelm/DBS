**********************************************************************
* Workload management

Sharing tools for production, analysis, private productions, ...
One set should be able to cope with all the cases.  Mindset:
production should be able to use tools for analysis.

Using different grids and batch systems.  Local vs. global
submission.

Generating chains of jobs (cmkin, oscar, orca, dst, ntuple).

Job splitting.

User specification

Gets data atoms from data management (self-consistent units of data
with some unique key, suitable for scalable and manageable
partitioning of jobs), negotiates job splitting.

WM needs to discover from dm where data is, then tell framework what
data to process and how to access it at the site.  As baseline will go
to dataset bookkeeping system, then dataset location service, submit
to resource broker / batch queue, jobs land on site, discover from
site configuration where the data is (local catalogue and/or rules
to create PFNs); no site-specific information will go with the job,
it is all discovered at the site.

In future resource broker may negotiate job splitting with dm (data
location service in particular), but this is more complex than "just
get list of locations" -- two-way negotiation of offering chunks,
offering job split, getting available location list. Not however
baseline system.

What needs to go with the job: meta data (event directory?) from
dataset bookkeeping system, other dm-provided meta data, local
information (catalogue, PFNs).

Job splitting can happen at user level, wm level, mixed; user may give
only constraints (e.g. job run time, max amount of runs to process per
job?).  Splitting is a set of jobs with the same requirements =>
cluster that supports bulk operations (submit, query, status, cancel,
...) + access to individual jobs.  subjob number available at wm
level.  Authentication handshake.

UI-level splitting is what we do now and will be the baseline system.
Done by user, not data distribution, divided to job run-time etc.
Typically need to provide whole dataset; don't see user-level
splitting.

RB-level splitting; not possible with current brokers.  User defines
constraints (limit on # of jobs).  Need mechanism to negotiate split
with data management and resource broker.

In all cases, but especially in RB-level split, one significant issue
is mapping job split into parameters to be passed to cobra: input
collection and event range specification.

Basic requirement for resource broker is that of a queue system.
Baseline is: i want to run these sets of jobs on sites compatible
with these constraints.  Resource broker makes no decisions or
optimisation.

Jobs discover local configuration when they land on site.  Part of
VO-specific site configuration (source some environment script).
Includes local catalogue etc. contacts.  Available to the jobs the
same way as e.g. software is (shared file system typically).

Workload management chooses minimal set of files to process.
Finer grainer selection done by application, including use
of event directory.

Data block replica location and data quality attributes are
separate sub-services.

*** Job monitoring

*** Other stuff

in mcrunjob
 - module (evdservices) service to build datasets before ...
    - get assignment id -> query redb -> get list of files, parameters
    - transfer those files to your local system (outside evdservices)
    - run attachrun, fixcoll, ...
    - quick and dirty, originally written by julia
    - refactor, split out of mcrunjob, more general purpose tool
        -> publish service
        - also used at fnal to build datasets published in pubdb
        - uses other services to do the actual publishing
    - mission: prepare datasets for subsequent processing
       once files are available, whatever it takes to make those
       files together usable for analysis (could be largely suppressed
       with suitable changes to edm)

 - get parameters from refdb for jobs; refdb does job splitting,
   mcrunjob does not decide it - gets job splitting files, iterate
   over, create jobs
    - job definition constraints: how large my output files are,
      how long do i need to run, how many worker nodes are available,
      ... => quickly very complex decision, choose most important
      criterions -> data management criteria prevail
    - little in common with crab, overlapping functionality
    - discussion on integration of crab/mcrunjob/mcps?  not yet,
      should come from aprom

 - summary procedure
    - template scripts for jobs are also kept in refdb
    - contain commands to generate summary information
    - re-engineering proposal: mcrunjob high-level service
    - does: filters job stdout + uses some of assignment parameters
       - looks for carf resume run netlogger output; pointer to
         some important information to be used by attachrun
       - also cross section (error messages? not...)
       - now also file checksums, sizes, etc.
       - delivered to refdb with sendmail; sites that can't
         handle this send them by hand in batch (not scalable)
         maybe use agent type functionality to deliver the summary?
    - future considerations: refdb re-engineering (dm to be
      part of)

 - files are stored on local site in mass storage
    - files created on local disk of the worker node
    - site-specific job-creation-time to copy data off worker
      nodes to storage (stageing script)
    - reading could occur directly from mass storage, or copied in
    - now creating a zip file of all the files (lcg only for now)
    - unspoken assumption: all data in us goes to fnal, other to
      infn or cern (usmop -> fnal, follow convention to locate)
    - have capability to stage the files out wherever wanted
    - file removal after transfer to be handled

 - considering putting in validation tools, holding for discussion
   with data management group, nicola, within production group

 - next version will have whole new set of tools
    - timescales: new technology integration 8-12 months
       current version frozen for physics tdr, once completed, rolling
       technologies are available now, continuing development
    - xml configuration of jobs
    - better interface to batch systems
    - better runtime instrumentation

 - dataset bookkeeping service: how do you get .oracrc parameters
   to the job; if data movement needs to occur, how does that get
   invoked; prestaging hooks
    - MS1. dataset discovery; queries + presentation (maybe physh)
    - MS2. data block matching sites / workload management (crab)
    - MS3. registration dataset bookkeeping system
      - plugging into summary procedure
      - harvesting files from storage elements, taking file ownership
        and responsibility, moving vs. transferring
      - active integration with phedex
    - MSN. technical validation

    - two types of dataset discovery: what to run on
       data available, number of events, etc.

    - what is dataset bookkeeping service
      - metadata about dataset entities
      - create, populate, discover datasets, resolve for files
    - use cases
      - create/define dataset
         - in case of mc: request approval
         - real/production dataset: stream
         - different scopes: experiment-wide, smaller scopes
         - in: attributes; out: id
      - populate: add (lfn, attrs, dsid)
      - close dataset
      - import: create + populate in single go
      - browse/search: in: attributes; out: dsids of summary
    - how do you manage open blocks (or open datasets)
      - system + users need to know dataset (block) is open
      - need to be clear how we define our terms
      - sample / run range / quality attributes => will run over
      - authoritative source/site for blocks
      - site offers to serve certain blocks (and can go get on demand)
      - will open blocks be published?  no?  real latencies in system?
      - cvs-type tags on growing datasets (independent of blocks)
          - tag for data range as files/run range -> conference data
      - available units of division: what job can run on,
          what site will host
      - intermediate data management unit

   - "i want to analyse this run range in data set x"
      - user: how many events, how much luminosity, how much data touched
      - tool: how can i use the same info to split into jobs, with time
        constraints etc. -> N jobs that run at RAL, M at FNAL
   - luminosity integrated at appropriate levels
      - blocks are data management, not physics unit
      - luminosity stored in separate database, dm references to segments,
        approximate rough estimate in dataset bookkeeping system
   - when importing data for certain run range
      -> may map to inconvenient set of blocks ("laptop use case")
      -> blocks should map to usage patterns, may be reshuffled
   - organise mini-workshop with emilio: do files need to be resorted
      on output from online system, do events need to be ordered, periods
      of stable running conditions; go to run meetings for magnet meetings
      (by austin ball) -> ask for task force to consider these issues
   - owner-related information needs to be stored somehow
      group owner, pileup, transformation, ...

   - proposed implementation
      - relational dbms backend (not tied to specific database)
      - three principal schema components
          - dataset-level meta data
          - file-level meta data
          - file membership in datasets
      - client communication with web-enabled db server through
         higher-level interface (not db schema)

   - scenarios:
      - production manager assigns jobs to run at some site B, but
        input at site A, invokes some interface to make the input
        dataset available at site B

to be considered
 - file merging
 - 
