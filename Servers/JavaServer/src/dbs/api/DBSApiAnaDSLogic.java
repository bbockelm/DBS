/**
 $Revision: 1.10 $"
 $Id: DBSApiAnaDSLogic.java,v 1.10 2007/01/24 17:08:57 sekhri Exp $"
 *
 */

package dbs.api;
import java.sql.Connection;
import java.sql.ResultSet;
import java.sql.PreparedStatement;
import java.io.Writer;
import java.util.Hashtable;
import java.util.Vector;
import dbs.sql.DBSSql;
import dbs.util.DBSUtil;
import dbs.DBSException;

/**
* A class that has the core business logic of all the Analysis datasets APIs.  The signature for the API is internal to DBS and is not exposed to the clients. There is another class <code>dbs.api.DBSApi</code> that has an interface for the clients. All these low level APIs are invoked from <code>dbs.api.DBSApi</code>. This class inherits from DBSApiLogic class.
* @author sekhri
*/
public class DBSApiAnaDSLogic extends DBSApiLogic {
		
	/**
	* Constructs a DBSApiLogic object that can be used to invoke several APIs.
	*/

	DBSApiPersonLogic personApi = null;
	DBSApiData data = null;
	public DBSApiAnaDSLogic(DBSApiData data) {
		super(data);
		this.data = data;
		personApi = new DBSApiPersonLogic(data);
	}

	/**
	 * Lists all the definitions .  
	 * <code> <""/></code>
	 * @param conn a database connection <code>java.sql.Connection</code> object created externally.
	 * @param out an output stream <code>java.io.Writer</code> object where this method writes the results into.
	 * @param patternName a parameter passed in from the client that can contain wild card characters for analysis dataset defination name. This pattern is used to restrict the SQL query results by sustitution it in the WHERE clause.
	 * @throws Exception Various types of exceptions can be thrown. Commonly they are thrown if the supplied lfn is invalid, the database connection is unavailable or the file is not found.
	 */
	 public void listAnalysisDatasetDefinition(Connection conn, Writer out, String patternName) throws Exception {
		PreparedStatement ps = null;
		ResultSet rs =  null;
		try {
			ps = DBSSql.listAnalysisDatasetDefinition(conn, getPattern(patternName, "pattern_analysis_dataset_definition_name"));
			rs =  ps.executeQuery();
			while(rs.next()) {
				out.write(((String) "<analysis_dataset_definition id='" +  get(rs, "ID") +
					"' analysis_dataset_definition_name='" + get(rs, "ANALYSIS_DATASET_DEFINITION_NAME") +
					"' lumi_sections='" + get(rs, "LUMI_SECTIONS") +
					"' lumi_section_ranges='" + get(rs, "LUMI_SECTION_RANGES") +
					"' runs='" + get(rs, "RUNS") +
					"' runs_ranges='" + get(rs, "RUNS_RANGES") +
					"' algorithms='" + get(rs, "ALGORITHMS") +
					"' lfns='" + get(rs, "LFNS") +
					"' path='" + get(rs, "PATH") +
					"' tiers='" + get(rs, "TIERS") +
					"' analysis_dataset_names='" + get(rs, "ANALYSIS_DATASET_NAMES") +
					"' user_cut='" + get(rs, "USER_CUT") +
					"' creation_date='" + getTime(rs, "CREATION_DATE") +
					"' last_modification_date='" + get(rs, "LAST_MODIFICATION_DATE") +
					"' created_by='" + get(rs, "CREATED_BY") +
					"' last_modified_by='" + get(rs, "LAST_MODIFIED_BY") +
					"'/>\n"));
			}
		} finally { 
			if (rs != null) rs.close();
			if (ps != null) ps.close();
		}
	 }



 	/**
	 * Insert a analysis dataset whose parameters are provided in the passed dataset <code>java.util.Hashtable</code>. This hashtable is generated externally and filled in with the analysis dataset parameters by parsing the xml input provided by the client. This method inserts entry into more than one table associated with AnalysisDataset table. The the main query that it executes to insert in AnalysisDataset table, get generated by <code>dbs.DBSSql.insertAnalysisDataset</code> method.<br> 
	 * First it fetches the userID by using the parameters specified in the dbsUser <code>java.util.Hashtable</code> and if the user does not exists then it insert the new user in the Person table. All this user operation is done by a private method getUserID. <br>
	 * Then it insert a new type field in AnalysisDSType table by calling a generic private  insertName method. <br>
	 * Then it insert a new status field in AnalysisDSStatus table by calling a generic private  insertName method. <br>
	 * Then it insert a new analysis dataset in AnalysisDataset table. <br>
	 * @param conn a database connection <code>java.sql.Connection</code> object created externally.
	 * @param out an output stream <code>java.io.Writer</code> object where this method writes the results into.
	 * @param dataset a  <code>java.util.Hastable</code>  that contain all the necessary key value pairs required for inserting a new analysis dataset. The keys along with its values that it may or may not contain are <br>
	 * <code>name, type, status, annotation, physics_group_name, created_by, creation_date </code> <br>
	 * @param dbsUser a <code>java.util.Hashtable</code> that contains all the necessary key value pairs for a single user. The most import key in this table is the user_dn. This hashtable is used to insert the bookkeeping information with each row in the database. This is to know which user did the insert at the first place.
	 * @throws Exception Various types of exceptions can be thrown. Commonly they are thrown if the supplied parameters in the hashtable are invalid, the database connection is unavailable or a duplicate entry is being added.
	 */
         public void createAnalysisDatasetFromPD(Connection conn, Writer out, Hashtable dataset, Hashtable dbsUser) throws Exception { 
		String name = get(dataset, "name", true);
		String type = get(dataset, "type", true);
		String status = get(dataset, "status", true);
		String lmbUserID = personApi.getUserID(conn, dbsUser);
		String cbUserID = personApi.getUserID(conn, get(dataset, "created_by", false), dbsUser );
		String creationDate = getTime(dataset, "creation_date", false);

		String procDSID = (new DBSApiProcDSLogic(this.data)).getProcessedDSID(conn, get(dataset, "path"), true);

		//FIXME Parentage of Analysis Datasets (not well understood yet)
		//Vector parentVector = DBSUtil.getVector(dataset,"parent");

		//FIXME   Make sure that Type and Status fileds are well understood
		//        will they pre-exist, or user can define as they create AnalysisDS ??     

		insertName(conn, out, "AnalysisDSType", "Type", type , cbUserID, lmbUserID, creationDate);
		insertName(conn, out, "AnalysisDSStatus", "Status", status, cbUserID, lmbUserID, creationDate);

	        ResultSet rsLumi = null;
                PreparedStatement psLumi = null; 
		try { 
			psLumi = DBSSql.listLumiSections(conn, procDSID); 
			PreparedStatement ps = null;
			try {
				ps = DBSSql.insertAnalysisDataset(conn,
		   				getStr(dataset, "annotation", true),
		   				name,
		   				psLumi.toString(),
		   				procDSID,
		   				getID(conn, "AnalysisDSType", "Type", type, true),
						getID(conn, "AnalysisDSStatus", "Status", status, true),
						getID(conn, "PhysicsGroup", "PhysicsGroupName", 
							get(dataset, "physics_group_name", true), 
							true), 
						cbUserID, lmbUserID, creationDate); 
                                                
				ps.execute();
			 } finally {
				if (ps != null) ps.close();   
			 }

			 //System.out.println("ANZAR: procDSID="+procDSID);
			 //ID of just added AnalysisDS 
			 String analysisDSID = getID(conn, "AnalysisDataset", "Name", name , true);
                 
			  //For eacxh run belonging to this ProcDS, get LumiSections and
			  //make an entry into AnalysisDatasetLumi

			  rsLumi =  psLumi.executeQuery(); 
			  while(rsLumi.next())    
				insertMap(conn, out, "AnalysisDatasetLumi", "AnalysisDataset", "Lumi",  
	 					analysisDSID, 
						get(rsLumi, "ID"), 
						cbUserID, lmbUserID, creationDate);
			  
		} finally {
                          if (psLumi != null) psLumi.close();
                          if (rsLumi != null) rsLumi.close();
		}
         }
	 

		
        public void createAnalysisDatasetDefination(Connection conn, Writer out, Hashtable table, Hashtable dbsUser) throws Exception { 
		String adsDefName = get(table, "analysisds_def_name", true);
		String path = get(table, "path", false);
		String userCut = get(table, "user_cut");
		String desc = getStr(table, "description", true);
		Vector lumiVector = DBSUtil.getVector(table, "lumi_section");
		Vector runVector = DBSUtil.getVector(table, "run");
		Vector tierVector = DBSUtil.getVector(table, "data_tier");
		Vector algoVector = DBSUtil.getVector(table, "algorithm");
		Vector fileVector = DBSUtil.getVector(table, "file");
		Vector adsVector = DBSUtil.getVector(table, "analysis_dataset");

		String lumiNumberList = "";
		String lumiRangeList = "";
		String runNumberList = "";
		String runRangeList = "";
		String tierList = "";
		String algoList = "";
		String fileList = "";
		String adsList = "";

		for (int j = 0; j < lumiVector.size(); ++j) {
			Hashtable hashTable = (Hashtable)lumiVector.get(j);
			String lumiNumber = get(hashTable, "lumi_section_number");
			String lumiRange = get(hashTable, "lumi_section_range");
			if(!isNull(lumiNumber)) {
				if(!isNull(lumiNumberList)) lumiNumberList += ",";
				lumiNumberList += lumiNumber;
			}
			if(!isNull(lumiRange)) {
				if(!isNull(lumiRangeList)) lumiRangeList += ",";
			       	lumiRangeList += pasreRange(lumiRange);
			}
	 	}
		for (int j = 0; j < runVector.size(); ++j) {
			Hashtable hashTable = (Hashtable)runVector.get(j);
			String runNumber = get(hashTable, "run_number");
			String runRange = get(hashTable, "run_range");
			if(!isNull(runNumber)) {
				if(!isNull(runNumberList)) runNumberList += ",";
			       	runNumberList += runNumber;
			}
			if(!isNull(runRange)) {
				if(!isNull(runRangeList)) runRangeList += ",";
				runRangeList += pasreRange(runRange);
			}
	 	}
		for (int j = 0; j < tierVector.size(); ++j) {
			if(!isNull(tierList)) tierList += ",";
			tierList += get((Hashtable)tierVector.get(j), "tier_name", true);
	 	}
		for (int j = 0; j < fileVector.size(); ++j) {
			if(!isNull(fileList)) fileList += ",";
			fileList += get((Hashtable)fileVector.get(j), "lfn", true);
	 	}
		for (int j = 0; j < adsVector.size(); ++j) {
			if(!isNull(adsList)) adsList += ",";
			adsList += get((Hashtable)adsVector.get(j), "analysis_dataset_name", true);
	 	}
		for (int j = 0; j < algoVector.size(); ++j) {
			Hashtable hashTable = (Hashtable)algoVector.get(j);
			if(!isNull(algoList)) algoList += ",";
			algoList +=  get(hashTable, "app_version", true) + 
				";" + get(hashTable, "app_family_name", true) + 
				";" + get(hashTable, "app_executable_name", true) + 
				";" + get(hashTable, "ps_hash", true);
	 	}
		createAnalysisDatasetDefination(conn, out, adsDefName, path, lumiNumberList, lumiRangeList, 
				runNumberList, runRangeList, tierList, fileList, adsList, algoList, userCut, desc,
				personApi.getUserID(conn, get(table, "created_by", false), dbsUser ),
				personApi.getUserID(conn, dbsUser),
				getTime(table, "creation_date", false) );

	 }
	 
         private void createAnalysisDatasetDefination(Connection conn, Writer out, 
			 String adsDefName, String path,
			 String lumiNumberList, String lumiRangeList, 
			 String runNumberList, String runRangeList, 
			 String tierList, String fileList, 
			 String adsList, String algoList, 
			 String userCut, String desc,
			 String cbUserID, String lmbUserID, 
			 String creationDate) throws Exception { 
		 if( getID(conn, "AnalysisDSDef", "Name", adsDefName, false) == null ) {
			PreparedStatement ps = null;
			try {
				ps = DBSSql.insertAnalysisDatasetDefination(conn, 
						adsDefName, 
						path, 
						lumiNumberList, 
						lumiRangeList, 
						runNumberList, 
						runRangeList, 
						tierList, 
						fileList, 
						adsList, 
						algoList, 
						userCut,
						desc,
						cbUserID, 
						lmbUserID, 
						creationDate);
				ps.execute();
			} finally {
				if (ps != null) ps.close();
			}

		} else {
			//Instead of warnning it is throwing an exception because the clients will know that there already exists 
			//a definition and he/she needs to create a new one. Warnning can be ignored but exception cannot.
			//writeWarning(out, "Already Exists", "1020", "Analysis Dataset Defintaion " + adsDefName + " Already Exists");
			throw new DBSException("Already Exists", "1020", "Analysis Dataset Defintaion " + adsDefName + " Already Exists");
		}

	 }
	 
         //public void createAnalysisDataset(Connection conn, Writer out, String analysisDatasetDefinitionName, Hashtable dbsUser) throws Exception {
         public void createAnalysisDataset(Connection conn, Writer out, Hashtable table, Hashtable dbsUser) throws Exception {

		//Get the Definition of the analysis dataset first and get the path and its id to be used for inserting analysis dataset
		String anaDSDefID = ""; 
		String procDSID = ""; 
		String lumiNumberList = ""; 
		String runNumberList = ""; 
		String tierList = ""; 
		String tierIDList = ""; 
		String fileList = ""; 
		String adsList = ""; 
		String algoList = ""; 
		String algoIDList = ""; 
		String userCut = "";
		Vector lumiRangeList = new Vector(); 
		Vector runRangeList = new Vector(); 

		PreparedStatement ps = null;
		ResultSet rs =  null;
		try {
			ps = DBSSql.listAnalysisDatasetDefinition(conn, get(table, "analysisds_def_name", true));
			rs =  ps.executeQuery();
			if(rs.next()) {
				anaDSDefID = get(rs, "ID");
				procDSID = getProcessedDSID(conn, get(rs, "PATH"), true);
				lumiNumberList = get(rs, "LUMI_SECTIONS");
				lumiRangeList = pasreRangeList(get(rs, "LUMI_SECTION_RANGES"));
				runNumberList = get(rs, "RUNS");
				runRangeList = pasreRangeList(get(rs, "RUNS_RANGES"));
				tierList = get(rs, "TIERS");
				fileList = get(rs, "LFNS");
				adsList = get(rs, "ANALYSIS_DATASET_NAMES");
				algoList = get(rs, "ALGORITHMS");
				userCut = get(rs, "USER_CUT");
			
			} else {
				throw new DBSException("Unavailable data", "1008", "No such analysis dataset definition " + analysisDatasetDefinitionName );
			}
		} finally { 
			if (rs != null) rs.close();
			if (ps != null) ps.close();
		}


		//Get all the tier IDs
		if(!isNull(tierList)) {
			String[] data = tierList.split(",");
			for (int i = 0; i != data.length ; ++i) {
				if(!isNull(tierIDList)) tierIDList += ",";
				tierIDList += getID(conn, "DataTier", "Name", data[i], true);
			}
		}

		//Get all the algo IDs
		if(!isNull(algoList)) {
			String[] algo = algoList.split(",");
			for (int i = 0; i != algo.length ; ++i) {
				String data[] = algo[i].split(";");
				if (data.length != 4) throw new DBSException("Invalid format", "1066", "Algorithm not stored in proper format in AnalysisDSDef Table. Proper format is version1;family1;exe1;pshash1,vrsion2;family2;exe2;pshash Given " + algo[i]);
				if(!isNull(algoIDList)) algoIDList += ",";
				algoIDList += getAlgorithmID(conn, data[0], data[1], data[2],data[3], true);
			}
		}

		

		//Insert a row in AnalysisDataset Table
		String analysisDatasetName = get(table, "name", true); 
		String status = get(file, "status", false);
		String type = get(file, "type", false);

		//FIXME Dafults should no be set by the server
		if (isNull(status)) status = "VALID";
		if (isNull(type)) type = "TEST";

		String adsID = "";
		if( isNull((adsID = getID(conn, "AnalysisDataset", "Name", analysisDatasetName, false)))) {
			PreparedStatement ps = null;
			try {
				ps = DBSSql.insertAnalysisDataset(conn, 
						analysisDatasetName,
						get(table, "annotation", false),
						procDSID,
						anaDSDefID,
						getID(conn, "AnalysisDSType", "Type", type, true);
						getID(conn, "AnalysisDSStatus", "Status", status, true);
						"",//FIXME Parent is debatable
						getID(conn, "PhysicsGroup", "PhysicsGroupName", 
							 get(table, "physics_group_name", true),
 							 true),
						cbUserID, lmbUserID, creationDate);
				ps.execute();
			} finally { 
				if (ps != null) ps.close();
			}
		} else {
			//Write waring message that analysis dataset exists already
			writeWarning(out, "Already Exists", "1020", "AnalysisDataset " + analysisDatasetName + " Already Exists");
		}
		
		//Fetch the analysis dataset id if not null, that just got inserted
		if(isNull(adsID)) adsID = getID(conn, "AnalysisDataset", "Name", analysisDatasetName, false);
		

		//Insert the contents of the analysis dataset in the AnalysisDSFileLumi map table
		ps = null;
		try {
			ps = DBSSql.insertAnalysisDSFileLumi(conn, 
					analysisDatasetName,
					get(table, "annotation", false),
					procDSID,
					anaDSDefID,
					getID(conn, "AnalysisDSType", "Type", type, true);
					getID(conn, "AnalysisDSStatus", "Status", status, true);
					"",//FIXME Parent is debatable
					getID(conn, "PhysicsGroup", "PhysicsGroupName", 
						 get(table, "physics_group_name", true),
 						 true),
					cbUserID, lmbUserID, creationDate);
			ps.execute();
		} finally { 
			if (ps != null) ps.close();
		}

		
	
	 }
 
	 private String pasreRange(String range) throws Exception {
		String[] data = range.split(",");
		if(data.length != 2) {
			throw new DBSException("Invalid format", "1037", " Expected a range in format number,number given " + range);
		}
		return data[0] + " AND " + data[1];
	}

	private Vector pasreRangeList(String range) throws Exception {
		Vector v = new Vector();
		if(isNull(range)) return v;
		String[] data = range.split(",");
		if(data.length == 0) {
			return v
		}
		for (int i = 0; i != data.length ; ++i) v.add(data[i]);
		return v;
	}

}
