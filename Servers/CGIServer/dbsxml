#!/usr/bin/env perl

######################################################################
# This is the CGI-based server for querying the DBS database.  Queries
# are made as HTTP GET requests.  Responses come as text/plain result,
# with some additional DBS-specific reply headers.  Usually the result
# is in XML.  See the PythonAPI for the client side of this exchange.
#
# The server is hosted on CERN web servers and accesses the DBS Oracle
# database hosted at CERN.
#
# This server script requires the following additional components:
#  - Database parameter file which defines the database contact and
#    authentication parameters.  This file is stored in AFS directory
#    only accessible to DBS admins and the web server itself.  This
#    is currently /afs/cern.ch/cms/aprom/DBS/DBAccessInfo/DBParam.
#  - PhEDEx toolkit modules, which currently implement DBS access.
#    These are currently in /afs/cern.ch/cms/aprom/phedex/PHEDEX.
#  - Extra perl modules and the Oracle instant client libraries.
#    These are currently in /afs/cern.ch/cms/aprom/phedex/Tools.
#   
# The details about the query are returned in three extra HTTP reply
# headers: dbs-status-{code,message,detail}, plus the reply body.
# Of these, dbs-status-code and -message are always given; the former
# is a numeric code and the latter a textual version.  The third
# header dbs-status-detail may be present in errors and may explain
# in more detail what went wrong.  The status codes are as follows:
#
#  100      Success, reply body contains result
#  200-299  The request itself was not accepted by the server.
#  300-399  The parameters supplied in the request were not accepted.
#  400-499  The request was well-formed, but a runtime error occurred.
#  500-599  Requested data does not exist.

######################################################################
# Prepare the environment.  We can't source the environment setup
# scripts since they are for bourne shell.  Just hardcode minimal set.

BEGIN {
  if (! $ENV{MOD_PERL})
  {
    use strict; use warnings; $^W=1; use Config;
    if (! $ENV{TNS_ADMIN} || ! $ENV{ORACLE_HOME}) {
      $ENV{TNS_ADMIN} = "/afs/cern.ch/project/oracle/admin";
      $ENV{ORACLE_HOME} = "/afs/cern.ch/project/oracle/\@sys/9203";
      $ENV{LD_LIBRARY_PATH} = "/afs/cern.ch/project/oracle/\@sys/9203/lib";
      exec { $0 } $0, @ARGV or die "cannot reset environment\n";
    }

    if ($Config{archname} =~ /solaris/) {
      unshift(@INC, "/afs/cern.ch/cms/aprom/DBS/ToolsForCMSDOC/perl-modules/lib/$Config{archname}");
      unshift(@INC, "/afs/cern.ch/cms/aprom/DBS/ToolsForCMSDOC/perl-modules/lib");
    } else {
      unshift(@INC, "/afs/cern.ch/cms/aprom/phedex/Tools/perl-modules/lib/$Config{archname}");
      unshift(@INC, "/afs/cern.ch/cms/aprom/phedex/Tools/perl-modules/lib");
    }
    unshift(@INC, "/afs/cern.ch/cms/aprom/phedex/PHEDEX/Toolkit/Common");
  } 
}

use CGI qw(header param);
use UtilsDBS;
use UtilsDB;

######################################################################
# Main program

my $dbparams = "/afs/cern.ch/cms/aprom/DBS/DBAccessInfo/DBParam";

# Known API calls
my %apis = (
  'getDatasetProvenance' => [ \&getDatasetProvenance, {
    api => REQUIRED, path => REQUIRED, datatier => OPTIONAL } ],
  'getDatasetContents' => [ \&getDatasetContents, {
    api => REQUIRED, path => REQUIRED } ],
  'getDatasetFiles' => [ \&getDatasetFiles, {
    api => REQUIRED, path => REQUIRED } ],
  'listDatasets' => [ \&listDatasets, {
    api => REQUIRED, pattern => OPTIONAL } ]);

# Get parameters
my $api = param('api');
&reply_failure (200, "Bad request", "API call was not defined")
  if (! defined $api);
&reply_failure (300, "Bad data", "Requested API call was not recognised")
  if (! exists $apis{$api});

&checkParameters ($apis{$api}[1]);
&{$apis{$api}[0]} ();

######################################################################
# Common routines.

# Make sure the call is valid.  Make sure all required arguments are
# present, and reject any excess arguments.
sub checkParameters
{
  my ($params) = @_;
  my @excess = grep (! exists $$params{$_}, param());
  my @missing = grep ($$params{$_}{REQUIRED} && ! defined param($_), keys %$params);
  if (@excess || @missing)
  {
    my $err = "";
    $err .= "Excess parameters @excess\n" if @excess;
    $err .= "Missing required parameters @missing\n" if @missing;
    &reply_failure (200, "Bad request", $err);
  }
}

# Validate a path.
sub getPath
{
  my $path = param('path');
  &reply_failure (200, "Bad request", "No path specified")
    if (! defined $path);
  &reply_failure (300, "Bad data", "Unsafe characters in path")
    if ($path !~ m|^[-A-Za-z0-9_./]+$|);
  &reply_failure (300, "Bad data", "Expected path of the form DATASET/TIER/OWNER")
    if ($path !~ m|^/([^/]+)/([^/]+)/([^/]+)$|);

  return ($1, $2, $3);
}

# Connect to the DBS database.
sub connectToDBS
{
  my $dbs = eval { UtilsDBS->connect ("DBS", "$dbparams:Production/Reader"); };
  &reply_failure (400, "Database connection failure", $@) if $@;
  &reply_failure (401, "Failed to connect to DBS", "") if ! $dbs;
  $SIG{INT} = 'DEFAULT'; # Restore ORACLE's swallowed signals.
  return $dbs;
}

# Print standard response headers.  We always print two extra response
# headers, "dbs-status-code:" and "dbs-status-message:", the former a
# numeric value and the latter the same in clear language.  In case of
# errors we may also add "dbs-status-detail:" header to expand on the
# cause of the error.
sub response_headers
{
  my ($code, $msg, $detail) = @_;
  my %args = (-dbs_status_code => $code,
  	      -dbs_status_message => $msg);
  if (defined $detail)
  {
    $detail =~ s/\n/ /sg;
    $args{dbs_status_detail} = $detail;
  }
  print header (-type => 'text/plain', %args);
}

# Generate a failure reply.
sub reply_failure
{
  my ($code, $msg, $detail, @info) = @_;
  unlink (@tmpfiles);
  &response_headers ($code, $msg, $detail);
  print @info;
  exit (1);

}

# Generate a success reply.
sub reply_success
{
  my (@data) = @_;
  unlink (@tmpfiles);
  &response_headers (100, "Success", undef);
  print @data;
  exit (0);
}

######################################################################
######################################################################
######################################################################
# Actual API implementation routines.  We code many of the queries for
# better efficiency directly against the schema as UtilsDBS isn't well
# geared for our purposes right now.

######################################################################
# List available (processed) datasets.
sub listDatasets
{
  use Text::Glob 'glob_to_regex';
  $Text::Glob::strict_wildcard_slash = 0;

  # If a pattern was given, make sure it's a valid one and convert to
  # a perl regular expression.  The patterns are shell globs.
  my $pattern = param('pattern');
  my $rxpattern = undef;
  if (defined $pattern && $pattern ne '')
  {
    eval { $rxpattern = &glob_to_regex ($pattern) };
    &reply_failure (300, "Bad data", "Invalid match pattern") if $@;
  }

  # Fetch the list of datasets from the database.
  my $dbs;
  eval
  {
    $dbs = &connectToDBS ();
    my $q = &dbexec($dbs->{DBH}, qq{
      select
        procds.id,
        primds.name,
        procds.name,
        dt.name
      from t_processed_dataset procds
        join t_primary_dataset primds
          on primds.id = procds.primary_dataset
        join t_processing_path ppath
          on ppath.id = procds.processing_path
        join t_data_tier dt
          on dt.id = ppath.data_tier});

    my $out = "<?xml version='1.0' standalone='yes'?>\n<dbs>\n";
    while (my ($id, $primary, $processed, $tier) = $q->fetchrow())
    {
      my $token = "/$primary/$tier/$processed";
      next if (defined $rxpattern && $token !~ m/$rxpattern/o);
      $out .= "  <processed-dataset id='$id' path='$token'/>\n";
    }
    $out .= "</dbs>\n";

    # Spit out the result
    $dbs->disconnect ();
    &reply_success ($out);
  };

  # If there was a failure, spit out an error.  Note that "exit" is a
  # special "die" call under mod_perl, so handle it gracefully.
  exit if $@ && ref $@ eq 'APR::Error' && $@ == ModPerl::EXIT;
  if ($@) { $@ =~ s/\n$//s; &reply_failure (402, "Execution error", $@) }
  eval { $dbs->disconnect () if $dbs };
}

######################################################################
# Get dataset provenance.
sub getDatasetProvenance
{
  # Parse parameters.  If 'datatier' is given, supply only ansers
  # matching those datatiers (comma-separated list of data tiers).
  my @path = &getPath ();
  my $parentspec = param('datatier');
  &reply_failure (300, "Bad data", "Unsafe characters in datatier")
    if (defined $parentspec && $parentspec !~ m|^[A-Za-z,]+$|);

  # Fetch dataset provenance.
  my $dbs;
  eval
  {
    # Connect to the database.
    $dbs = &connectToDBS ();

    # Verify all requested datatiers are known
    $dbs->fetchAll ("data_tier");
    $dbs->fetchAll ("parentage_type");
    my @parents = (defined $parentspec ? split(",", $parentspec) : ());
    foreach my $t (@parents)
    {
      if (! grep ($_->{NAME} eq $t, @{$$dbs{PARENTAGE_TYPE}}))
      {
	$dbs->disconnect ();
	&reply_failure (301, "Bad parentage", "Parentage type '$t' not known");
      }
    }

    # Translate the dataset path to an id
    my $id = &datasetFromPath ($dbs, @path);

    # Fetch provenance info
    my $qdsinputs = &dbexec ($dbs->{DBH}, qq{
	select distinct
	    pt.name,
	    procds.id,
	    ppath.data_tier,
	    primds.name,
	    procds.name
	from t_event_collection ec
	join t_evcoll_parentage ep
	  on ep.child = ec.id
	join t_event_collection ec2
	  on ec2.id = ep.parent
	join t_processed_dataset procds
	  on procds.id = ec2.processed_dataset
	join t_processing_path ppath
	  on ppath.id = procds.processing_path
	join t_primary_dataset primds
	  on primds.id = procds.primary_dataset
	join t_parentage_type pt
	  on pt.id = ep.type
	where ec.processed_dataset = :id},
	":id" => $id);

    my $out = "<?xml version='1.0' standalone='yes'?>\n<dbs>\n";
    $out .= "  <processed-dataset id='$id' path='/$path[0]/$path[1]/$path[2]'>\n";
    while (my ($type, $id, $tier, $primary, $processed) = $qdsinputs->fetchrow())
    {
      next if defined $parentspec && ! grep ($type eq $_, @parents);
      $tier = (grep($_->{ID} eq $tier, @{$$dbs{DATA_TIER}}))[0]->{NAME};
      $out .= "    <parent path='/$primary/$tier/$processed' tier='$tier' type='$type' id='$id'/>\n";
    }
    $out .= "  </processed-dataset>\n";
    $out .= "</dbs>\n";

    # Spit out the result
    $dbs->disconnect ();
    &reply_success ($out);
  };

  # If there was a failure, spit out an error.  Note that "exit" is a
  # special "die" call under mod_perl, so handle it gracefully.
  exit if $@ && ref $@ eq 'APR::Error' && $@ == ModPerl::EXIT;
  if ($@) { $@ =~ s/\n$//s; &reply_failure (402, "Execution error", $@) }
  eval { $dbs->disconnect () if $dbs };
}

######################################################################
# Get the contents of the dataset: the blocks and event collections.
# FIXME: Replace event collections with files.
sub getDatasetContents
{
  # Parse parameters
  my @path = &getPath ();

  # Fetch the contents
  my $dbs;
  eval
  {
    # Connect to the database.
    $dbs = &connectToDBS ();

    # Translate the dataset path to an id
    my $id = &datasetFromPath ($dbs, @path);

    # Prepare output.
    my $out = "<?xml version='1.0' standalone='yes'?>\n<dbs>\n";
    my $pathname = "/$path[0]/$path[1]/$path[2]";
    $out .= "  <processed-dataset id='$id' path='$pathname'>\n";

    # Fetch blocks, event collections and files
    my ($blocks, $evcolls, $files) = &datasetContents ($dbs, $id);
    foreach my $block (@$blocks)
    {
      $out .= "    <block id='$$block{ID}' name='$pathname#$$block{ID}'>\n";
      foreach my $evc (sort { $$a{NAME} cmp $$b{NAME} } values %{$$block{EVCS}})
      {
	next if $$evc{NAME} eq 'EvC_META';
	my $name = $$evc{NAME}; $name =~ s/^EvC_Run//;
	$out .= "      <event-collection name='$name' events='$$evc{EVENTS}'/>\n";
      }
      $out .= "    </block>\n";
    }
    $out .= "  </processed-dataset>\n";
    $out .= "</dbs>\n";

    # Spit out the result
    $dbs->disconnect ();
    &reply_success ($out);
  };

  # If there was a failure, spit out an error.  Note that "exit" is a
  # special "die" call under mod_perl, so handle it gracefully.
  exit if $@ && ref $@ eq 'APR::Error' && $@ == ModPerl::EXIT;
  if ($@) { $@ =~ s/\n$//s; &reply_failure (402, "Execution error", $@) }
  eval { $dbs->disconnect () if $dbs };
}

######################################################################
# Get the files and blocks of a dataset.
sub getDatasetFiles
{
  # Parse parameters
  my @path = &getPath ();

  # Fetch the contents
  my $dbs;
  eval
  {
    # Connect to the database.
    $dbs = &connectToDBS ();

    # Translate the dataset path to an id
    my $id = &datasetFromPath ($dbs, @path);

    # Prepare output.
    my $out = "<?xml version='1.0' standalone='yes'?>\n<dbs>\n";
    my $pathname = "/$path[0]/$path[1]/$path[2]";
    $out .= "  <processed-dataset id='$id' path='$pathname'>\n";

    # Fetch blocks, event collections and files
    my ($blocks, $evcolls, $files) = &datasetContents ($dbs, $id);
    foreach my $block (@$blocks)
    {
      $out .= "    <block id='$$block{ID}' name='$pathname#$$block{ID}'";
      $out .= " files='$$block{TOTAL_FILES}' bytes='$$block{TOTAL_BYTES}'>\n";
      foreach my $file (values %{$$block{FILES}})
      {
	$out .= "      <file id='$$file{ID}' inblock='$$file{INBLOCK}'";
        $out .= " guid='$$file{GUID}' lfn='$$file{LOGICAL_NAME}'";
        $out .= " checksum='$$file{CHECKSUM}' size='$$file{FILESIZE}'";
        $out .= " status='@{[$$file{STATUS} || '']}' type='$$file{TYPE}'/>\n";
      }
      $out .= "    </block>\n";
    }
    $out .= "  </processed-dataset>\n";
    $out .= "</dbs>\n";

    # Spit out the result
    $dbs->disconnect ();
    &reply_success ($out);
  };

  # If there was a failure, spit out an error.  Note that "exit" is a
  # special "die" call under mod_perl, so handle it gracefully.
  exit if $@ && ref $@ eq 'APR::Error' && $@ == ModPerl::EXIT;
  if ($@) { $@ =~ s/\n$//s; &reply_failure (402, "Execution error", $@) }
  eval { $dbs->disconnect () if $dbs };
}

######################################################################
# Schema utilities.
sub datasetFromPath
{
  my ($dbs, $primary, $tier, $processed) = @_;
  my ($id) = &dbexec($dbs->{DBH}, qq{
    select procds.id
    from t_processed_dataset procds
      join t_primary_dataset primds
        on primds.id = procds.primary_dataset
      join t_processing_path ppath
        on ppath.id = procds.processing_path
      join t_data_tier dt
        on dt.id = ppath.data_tier
    where procds.name = :procname
      and primds.name = :primname
      and dt.name = :tiername},
    ":procname" => $processed,
    ":tiername" => $tier,
    ":primname" => $primary)
    ->fetchrow ();

  if (! defined $id)
  {
    $dbs->disconnect ();
    &reply_failure (302, "Bad dataset",
      "The dataset /$primary/$tier/$processed does not exist");
  }

  return $id;
}

# Obtain bulk of dataset contents in a convenient data structure.
sub datasetContents
{
  my ($dbs, $id) = @_;
  my $blocks = &dbexec ($dbs->{DBH}, qq{
    select id, status, files total_files, bytes total_bytes from t_block
    where processed_dataset = :id}, ":id" => $id)
    ->fetchall_arrayref({});

  my $evcolls = &dbexec ($dbs->{DBH}, qq{
    select
      evc.id,
      evc.collection_index,
      evi.events,
      evi.name
    from t_event_collection evc
      join t_info_evcoll evi on evi.event_collection = evc.id
    where evc.processed_dataset = :id}, ":id" => $id)
    ->fetchall_arrayref({});

  my $files = &dbexec ($dbs->{DBH}, qq{
    select
      evc.id evcoll,
      f.inblock,
      f.id,
      f.guid,
      f.logical_name,
      f.checksum,
      f.filesize,
      fs.name status,
      ft.name type
    from t_event_collection evc
      join t_evcoll_file evf
	on evf.evcoll = evc.id
      join t_file f
	on f.id = evf.fileid
      left join t_file_status fs
	on fs.id = f.status
      join t_file_type ft
	on ft.id = f.type
    where evc.processed_dataset = :id}, ":id" => $id)
    ->fetchall_arrayref({});

  # Link blocks, event collections and files to each other.
  my %id2block = map { $$_{ID} => $_ } @$blocks;
  my %id2evcoll = map { $$_{ID} => $_ } @$evcolls;
  foreach my $file (@$files)
  {
    my $block = $id2block{$$file{INBLOCK}};
    my $evcoll = $id2evcoll{$$file{EVCOLL}};
    push(@{$$evcoll{FILES}}, $file);
    $$block{FILES}{$$file{ID}} = $file;
    $$block{EVCS}{$$file{EVCOLL}} = $evcoll;
  }

  return ($blocks, $evcolls, $files);
}
